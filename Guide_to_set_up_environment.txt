# ================================
# 1. Text Generation - oobabooga WebUI
# ================================
!git clone https://github.com/oobabooga/text-generation-webui
%cd text-generation-webui
!pip install -r requirements.txt
# Download a good model (Hermes 2 Pro / LLaMA 3 8B Q4_K_M)
!python download-model.py TheBloke/Hermes-2-Pro-Llama-3-8B-GGUF --hf-token ''  # No auth needed if using direct link

# ================================
# 2. Whisper.cpp for Speech-to-Text
# ================================
%cd /content
!git clone https://github.com/ggerganov/whisper.cpp
%cd whisper.cpp
!make
!bash ./models/download-ggml-model.sh large-v2

# ================================
# 3. Coqui TTS for Text-to-Speech
# ================================
%cd /content
!git clone https://github.com/coqui-ai/TTS
%cd TTS
!pip install -r requirements.txt

# ================================
# 4. Stable Diffusion XL (AUTOMATIC1111)
# ================================
%cd /content
!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
%cd stable-diffusion-webui
!pip install -r requirements.txt
# Download SDXL model manually or via wget:
!wget -O /content/stable-diffusion-webui/models/Stable-diffusion/sdxl.safetensors https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors

# ================================
# 5. StarCoder for Code Generation
# ================================
%cd /content
!git clone https://github.com/bigcode-project/starcoder
%cd starcoder
!pip install -r requirements.txt

# ================================
# 6. Stable DreamFusion for Text-to-3D
# ================================
%cd /content
!git clone https://github.com/ashawkey/stable-dreamfusion
%cd stable-dreamfusion
!pip install -r requirements.txt


'''Stable diffusion model used :v15PrunedEmaonly_v15PrunedEmaonly.safetensors
Download the model from stable diffusion open source platforms'''


!mkdir -p /content/riffusion
print("Created empty /content/riffusion")
print("Cloning public fork of Riffusion directly into /content/riffusion...")
!git clone https://github.com/riffusion/riffusion-inference.git /content/riffusion

# --- 2. Install Riffusion package ---
%cd /content/riffusion
!pip install -e 


# --- 6. Verify the final structure ---
print("\nFinal /content/riffusion structure:")
!ls -F /content/riffusion/

%cd /content/
!git clone https://github.com/huggingface/diffusers.git
%cd /content/diffusers
!pip install -e . # Install diffusers in editable mode to get scripts recognized
%cd /content/


!rm -rf /content/stable_diffusion_v1_5_diffusers # Ensure a clean start
!python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py \
    --checkpoint_path "/content/drive/MyDrive/v15PrunedEmaonly_v15PrunedEmaonly.safetensors" \
    --dump_path /content/stable_diffusion_v1_5_diffusers \
    --from_safetensors


# Verify after conversion
!ls -F /content/stable_diffusion_v1_5_diffusers/
!cat /content/stable_diffusion_v1_5_diffusers/model_index.json
!ls -l /content/stable_diffusion_v1_5_diffusers/unet/
!ls -l /content/stable_diffusion_v1_5_diffusers/vae/


'''Convert the stable diffusion .safetensors file contents to .bin files'''
#To convert run these commands with path to the .safetensors file


from safetensors.torch import save_file
import torch

# VAE example
vae_path = "/content/stable_diffusion_v1_5_diffusers/vae/diffusion_pytorch_model.bin"
vae_model = torch.load(vae_path, map_location="cpu")

# vae_model should be a dict of tensors, not a full nn.Module
if isinstance(vae_model, dict) and all(isinstance(v, torch.Tensor) for v in vae_model.values()):
    save_file(vae_model, vae_path.replace(".bin", ".safetensors"))
else:
    raise ValueError("Loaded model is not a state_dict. You must save a dict of tensors, not a full model.")
unet_path = "/content/stable_diffusion_v1_5_diffusers/unet/diffusion_pytorch_model.bin"
unet_model = torch.load(unet_path, map_location="cpu")

# vae_model should be a dict of tensors, not a full nn.Module
if isinstance(unet_model, dict) and all(isinstance(v, torch.Tensor) for v in unet_model.values()):
    save_file(unet_model, unet_path.replace(".bin", ".safetensors"))
else:
    raise ValueError("Loaded model is not a state_dict. You must save a dict of tensors, not a full model.")


#Cloning GitHub repositories and setting up

!pip install optimum torch FastAPI uvicorn numpy pydantic moviepy accelerate transformers==4.43.4 bark TTS diffusers>=0.30.0 huggingface_hub auto_gptq torchvision torchaudio scipy nest_asyncio jax jaxlib flax peft
!pip install --quiet git+https://github.com/suno-ai/bark.git
!apt update && apt install -y ffmpeg
!mkdir -p Wav2Lip/checkpoints
!gdown --id 1rwNnB0qgk7aZ_Y0dJ9IcHyCmbtK-TkPb -O Wav2Lip/checkpoints/wav2lip.pth

!mkdir -p offload
!mkdir -p offload_dir

# Clone all required repositories into /content
!git clone https://github.com/Rudrabha/Wav2Lip.git /content/Wav2Lip
!git clone https://github.com/Winfredy/SadTalker.git /content/SadTalker
#!git clone https://github.com/riffusion/riffusion.git /content/riffusion
!git clone https://github.com/facebookresearch/audiocraft.git /content/audiocraft
!git clone https://huggingface.co/TheBloke/OpenChat-3.5-0106-GPTQ /content/OpenChat-3.5-0106-GPTQ

%cd /content/Wav2Lip
!pip install -r requirements.txt

%cd /content/SadTalker
!pip install -r requirements.txt

%cd /content/riffusion
!pip install -r requirements.txt

%cd /content/audiocraft
!pip install -r requirements.txt
!pip install -e .

#Modify bark to adjust weights
#run following command to modify bark
!sed -i "s/torch.load(ckpt_path, map_location=device)/torch.load(ckpt_path,map_location=device, weights_only=False)/"/usr/local/lib/python3.12/dist-packages/bark/generation.py